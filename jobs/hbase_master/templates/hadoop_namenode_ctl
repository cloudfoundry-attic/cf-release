#!/bin/bash -e

HADOOP_PACKAGE_DIR="/var/vcap/packages/hadoop"
JOBS_DIR="/var/vcap/jobs/hbase_master"
LOG_DIR="/var/vcap/sys/log/hbase_master"
RUN_DIR="/var/vcap/sys/run/hbase_master"

HADOOP_BIN="${HADOOP_PACKAGE_DIR}/bin"
HADOOP_DATA_DIR="/var/vcap/store/hbase_master"
MASTER_HOSTNAME="<%= properties.hbase_master.hostname %>"
PIDFILE="${RUN_DIR}/hadoop-vcap-namenode.pid"
TMP_DIR="/var/vcap/store/hbase"

export HADOOP_CONF_DIR="${JOBS_DIR}/config/hadoop"
export HADOOP_IDENT_STRING="vcap"
export HADOOP_LOG_DIR=${LOG_DIR}
export HADOOP_NAMENODE_USER="vcap"
export HADOOP_PID_DIR=${RUN_DIR}
export JAVA_HOME="/var/vcap/packages/dea_jvm"

source /var/vcap/packages/common/utils.sh

case $1 in

  start)
    # hadoop-daemon.sh has its own pid guard,
    # we use ours for consistency anyway
    pid_guard $PIDFILE "hadoop_namenode"

    mkdir -p $RUN_DIR
    mkdir -p $LOG_DIR
    mkdir -p $HADOOP_DATA_DIR
    mkdir -p $TMP_DIR

    chown vcap:vcap $RUN_DIR
    chown vcap:vcap $LOG_DIR
    chown vcap:vcap $HADOOP_DATA_DIR
    chown vcap:vcap $TMP_DIR
    # Set maximum number of open file descriptors.
    ulimit -n 32768
    # Set maximum number of processes available to a single user.
    ulimit -u 32000

    if [ ! -d /var/vcap/store/hbase_master/name ]
    then
      cd "${HADOOP_PACKAGE_DIR}/bin"
      ./hadoop --config $HADOOP_CONF_DIR namenode -format
    fi

    # hadoop ctl scripts manage their pidfiles,
    # so we don't attempt to write ours
    exec chpst -u vcap:vcap $HADOOP_BIN/hadoop-daemon.sh --config $HADOOP_CONF_DIR start namenode \
         >>$LOG_DIR/hadoop_namenode_start.stdout.log \
         2>>$LOG_DIR/hadoop_namenode_start.stderr.log

    ;;

  stop)
    exec chpst -u vcap:vcap $HADOOP_BIN/hadoop-daemon.sh --config $HADOOP_CONF_DIR stop namenode \
         >>$LOG_DIR/hadoop_namenode_stop.stdout.log \
         2>>$LOG_DIR/hadoop_namenode_stop.stderr.log

    ;;

  *)
    echo "Usage: hadoop_namenode_ctl {start|stop}"

    ;;

esac
